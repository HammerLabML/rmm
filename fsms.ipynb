{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finite state machines\n",
    "\n",
    "In this notebook, we attempt to translate finite state machines into reservoir memory machines. We have two variations of this task. First, directly translate a known finite state machine into a reservoir memory machine and predict the correct output on long test sequences. Second, we generate all sequences of length up to the number of states+1, then infer a finite state machine from that training data using classical methods, and translate this FSM into a reservoir memory machine, which introduces another layer of complication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "task = 'fsms'\n",
    "\n",
    "# set up experimental hyperparameters\n",
    "num_states = 4\n",
    "num_in_symbols = 2\n",
    "num_out_symbols = 2\n",
    "# the number of test time series in each repeat\n",
    "N_test = 10\n",
    "\n",
    "# as training data for FSM inference, sample all possible input sequences of length\n",
    "# num_states + 1 over num_in_symbols\n",
    "Xs_inference = []\n",
    "stk = [[]]\n",
    "while stk:\n",
    "    prefix = stk.pop()\n",
    "    if len(prefix) == num_states + 1:\n",
    "        Xs_inference.append(prefix)\n",
    "        continue\n",
    "    for x in range(num_in_symbols):\n",
    "        stk.append(prefix + [x])\n",
    "\n",
    "import os\n",
    "# for evaluation, sample some long input sequences over the input alphabet and store them\n",
    "# for fair comparisons later on\n",
    "eval_seq_len = 256\n",
    "eval_seq_path = '%s_evaluation_sequences.csv' % task\n",
    "if os.path.isfile(eval_seq_path):\n",
    "    Xs_test = np.loadtxt(eval_seq_path, delimiter='\\t', dtype=int).T\n",
    "else:\n",
    "    Xs_test = np.random.randint(num_in_symbols, size=(N_test, eval_seq_len))\n",
    "    np.savetxt(eval_seq_path, Xs_test.T, delimiter='\\t', fmt='%d')\n",
    "\n",
    "# transform to one-hot-coding\n",
    "Xs_test_one_hot = []\n",
    "for X in Xs_test:\n",
    "    X_oh = np.zeros((len(X), num_in_symbols))\n",
    "    for t in range(len(X)):\n",
    "        X_oh[t, X[t]] = 1.\n",
    "    Xs_test_one_hot.append(X_oh)\n",
    "\n",
    "import fsm\n",
    "# set up a function to generate training data from a finite state machine,\n",
    "# either for the hard or the easy task\n",
    "def generate_seq(delta, rho, with_inference = False):\n",
    "    # if we wish to use automaton inference, first learn a surrogate automaton instead\n",
    "    # of the actual automaton\n",
    "    if with_inference:\n",
    "        # generate training data for automaton learning\n",
    "        Ys, _ = fsm.label_sequences(Xs_inference, delta, rho)\n",
    "        # learn the surrogate automaton\n",
    "        delta, rho = fsm.learn_fsm(Xs_inference, Ys)\n",
    "    # then generate training data, in particular all paths with at most one cycle\n",
    "    # through the finite state machine\n",
    "    paths = fsm.one_cyclic_paths(delta)\n",
    "    # convert them to training data for a reservoir memory machine\n",
    "    Xs = []\n",
    "    Qs = []\n",
    "    Ys = []\n",
    "    for path in paths:\n",
    "        # initialize input matrix, state array, and output array\n",
    "        X = np.zeros((len(path), delta.shape[1]))\n",
    "        Q = np.zeros(len(path))\n",
    "        Y = np.zeros((len(path), 1))\n",
    "        # convert the path\n",
    "        for t in range(len(path)):\n",
    "            q, x = path[t]\n",
    "            X[t, x] = 1.\n",
    "            Q[t] = q + 1\n",
    "            Y[t] = rho[q]\n",
    "        # append to training data\n",
    "        Xs.append(X)\n",
    "        Qs.append(Q)\n",
    "        Ys.append(Y)\n",
    "    if with_inference:\n",
    "        return Xs, Qs, Ys, delta, rho\n",
    "    else:\n",
    "        return Xs, Qs, Ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the hyper-parameter ranges for all models\n",
    "models = ['ESN', 'CRJ', 'LMU', 'RMM_ESN', 'RMM_CRJ', 'RMM_LMU']\n",
    "# all models get the same number of neurons\n",
    "m = 128\n",
    "hyperparam_ranges = {\n",
    "    'ESN' : {\n",
    "        'radius' : [0.5, 0.7, 0.9],\n",
    "        'sparsity' : [0.1, 0.2, 0.5],\n",
    "        'regul' : [1E-7, 1E-5, 1E-3]\n",
    "    },\n",
    "    'CRJ' : {\n",
    "        'v' : [0.1, 0.3, 0.5],\n",
    "        'w_c' : [0.1, 0.7, 0.9],\n",
    "        'w_j' : [0.1, 0.2, 0.4],\n",
    "        'l' : [4, 8, 16],\n",
    "        'regul' : [1E-7, 1E-5, 1E-3]\n",
    "    },\n",
    "    'LMU' : {\n",
    "        'regul' : [1E-7, 1E-5, 1E-3]\n",
    "    },\n",
    "    'RMM_ESN' : {\n",
    "        'radius' : [0.5, 0.7, 0.9],\n",
    "        'sparsity' : [0.1, 0.2, 0.5],\n",
    "        'regul' : [1E-7, 1E-5, 1E-3],\n",
    "        'C' : [1., 100., 10000.]\n",
    "    },\n",
    "    'RMM_CRJ' : {\n",
    "        'v' : [0.1, 0.3, 0.5],\n",
    "        'w_c' : [0.1, 0.7, 0.9],\n",
    "        'w_j' : [0.1, 0.2, 0.4],\n",
    "        'l' : [4, 8, 16],\n",
    "        'regul' : [1E-7, 1E-5, 1E-3],\n",
    "        'C' : [1., 100., 10000.]\n",
    "    },\n",
    "    'RMM_LMU' : {\n",
    "        'regul' : [1E-7, 1E-5, 1E-3],\n",
    "        'C' : [1., 100., 10000.]\n",
    "    }\n",
    "}\n",
    "\n",
    "import esn\n",
    "import crj\n",
    "import lmu\n",
    "import rmm\n",
    "\n",
    "# set up a function to initialize an instance for each model\n",
    "def setup_model(model, hyperparams):\n",
    "    # first, set up the correct reservoir and nonlinearity\n",
    "    if model.endswith('ESN'):\n",
    "        U, W = esn.initialize_reservoir(m, num_in_symbols, radius = hyperparams['radius'], sparsity = hyperparams['sparsity'])\n",
    "        nonlin = np.tanh\n",
    "    elif model.endswith('CRJ'):\n",
    "        U = crj.setup_input_weight_matrix(num_in_symbols, m, v = hyperparams['v'])\n",
    "        W = crj.setup_reservoir_matrix(m, w_c = hyperparams['w_c'], w_j = hyperparams['w_j'], l = hyperparams['l'])\n",
    "        nonlin = np.tanh\n",
    "    elif model.endswith('LMU'):\n",
    "        degree = int(m/num_in_symbols)-1\n",
    "        U, W = lmu.initialize_reservoir(num_in_symbols, degree, num_states+1)\n",
    "        nonlin = lambda x : x\n",
    "    else:\n",
    "        raise ValueError('Unknown model: %s' % model)\n",
    "    # then, set up the model\n",
    "    if not model.startswith('RMM_'):\n",
    "        net = esn.ESN(U, W, regul = hyperparams['regul'], input_normalization = False, nonlin = nonlin)\n",
    "    else:\n",
    "        net = rmm.RMM(U, W, regul = hyperparams['regul'], input_normalization = False, nonlin = nonlin, C = hyperparams['C'], q_0 = 1, discrete_prediction = True, svm_kernel = 'rbf')\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- repeat 1 of 10 ---\n",
      "-- model: ESN --\n",
      "best rmse: 0.265265\n",
      "-- model: CRJ --\n",
      "best rmse: 0.393867\n",
      "-- model: LMU --\n",
      "best rmse: 0.711471\n",
      "-- model: RMM_ESN --\n",
      "best rmse: 0\n",
      "-- model: RMM_CRJ --\n",
      "best rmse: 0\n",
      "-- model: RMM_LMU --\n",
      "best rmse: 0\n",
      "--- repeat 2 of 10 ---\n",
      "-- model: ESN --\n",
      "best rmse: 0.478202\n",
      "-- model: CRJ --\n",
      "best rmse: 0.39117\n",
      "-- model: LMU --\n",
      "best rmse: 0.449159\n",
      "-- model: RMM_ESN --\n",
      "best rmse: 0\n",
      "-- model: RMM_CRJ --\n",
      "best rmse: 0\n",
      "-- model: RMM_LMU --\n",
      "best rmse: 0\n",
      "--- repeat 3 of 10 ---\n",
      "-- model: ESN --\n",
      "best rmse: 0.411715\n",
      "-- model: CRJ --\n",
      "best rmse: 0.478991\n",
      "-- model: LMU --\n",
      "best rmse: 0.820361\n",
      "-- model: RMM_ESN --\n",
      "best rmse: 0\n",
      "-- model: RMM_CRJ --\n",
      "best rmse: 0\n",
      "-- model: RMM_LMU --\n",
      "best rmse: 0\n",
      "--- repeat 4 of 10 ---\n",
      "-- model: ESN --\n",
      "best rmse: 0.370682\n",
      "-- model: CRJ --\n",
      "best rmse: 0.558135\n",
      "-- model: LMU --\n",
      "best rmse: 0.406913\n",
      "-- model: RMM_ESN --\n",
      "best rmse: 0\n",
      "-- model: RMM_CRJ --\n",
      "best rmse: 0\n",
      "-- model: RMM_LMU --\n",
      "best rmse: 0\n",
      "--- repeat 5 of 10 ---\n",
      "-- model: ESN --\n",
      "best rmse: 0.27549\n",
      "-- model: CRJ --\n",
      "best rmse: 0.661906\n",
      "-- model: LMU --\n",
      "best rmse: 0.437425\n",
      "-- model: RMM_ESN --\n",
      "best rmse: 0\n",
      "-- model: RMM_CRJ --\n",
      "best rmse: 0\n",
      "-- model: RMM_LMU --\n",
      "best rmse: 0\n",
      "--- repeat 6 of 10 ---\n",
      "-- model: ESN --\n",
      "best rmse: 0.596245\n",
      "-- model: CRJ --\n",
      "best rmse: 0.584207\n",
      "-- model: LMU --\n",
      "best rmse: 1.13239\n",
      "-- model: RMM_ESN --\n",
      "best rmse: 0\n",
      "-- model: RMM_CRJ --\n",
      "best rmse: 0\n",
      "-- model: RMM_LMU --\n",
      "best rmse: 0\n",
      "--- repeat 7 of 10 ---\n",
      "-- model: ESN --\n",
      "best rmse: 0.656089\n",
      "-- model: CRJ --\n",
      "best rmse: 0.60189\n",
      "-- model: LMU --\n",
      "best rmse: 0.63988\n",
      "-- model: RMM_ESN --\n",
      "best rmse: 0\n",
      "-- model: RMM_CRJ --\n",
      "best rmse: 0\n",
      "-- model: RMM_LMU --\n",
      "best rmse: 0\n",
      "--- repeat 8 of 10 ---\n",
      "-- model: ESN --\n",
      "best rmse: 0.633542\n",
      "-- model: CRJ --\n",
      "best rmse: 0.584162\n",
      "-- model: LMU --\n",
      "best rmse: 0.466506\n",
      "-- model: RMM_ESN --\n",
      "best rmse: 0\n",
      "-- model: RMM_CRJ --\n",
      "best rmse: 0\n",
      "-- model: RMM_LMU --\n",
      "best rmse: 0.579264\n",
      "--- repeat 9 of 10 ---\n",
      "-- model: ESN --\n",
      "best rmse: 0.372293\n",
      "-- model: CRJ --\n",
      "best rmse: 0.376316\n",
      "-- model: LMU --\n",
      "best rmse: 0.373797\n",
      "-- model: RMM_ESN --\n",
      "best rmse: 0\n",
      "-- model: RMM_CRJ --\n",
      "best rmse: 0\n",
      "-- model: RMM_LMU --\n",
      "best rmse: 0\n",
      "--- repeat 10 of 10 ---\n",
      "-- model: ESN --\n",
      "best rmse: 0.321067\n",
      "-- model: CRJ --\n",
      "best rmse: 0.408364\n",
      "-- model: LMU --\n",
      "best rmse: 0.385313\n",
      "-- model: RMM_ESN --\n",
      "best rmse: 0\n",
      "-- model: RMM_CRJ --\n",
      "best rmse: 0\n",
      "-- model: RMM_LMU --\n",
      "best rmse: 0\n",
      "\n",
      "Selected the following hyper-parameters for ESN\n",
      "radius: 0.9\n",
      "sparsity: 0.5\n",
      "regul: 0.001\n",
      "errors: [0.30455653218353984, 0.5041386226343572, 0.46660393599819194, 0.47908218411402886, 0.3468681579977842, 0.6398488895523502, 0.7604107204101198, 0.6335423188938958, 0.39773978683128786, 0.3420157024515426]\n",
      "\n",
      "Selected the following hyper-parameters for CRJ\n",
      "v: 0.5\n",
      "w_c: 0.7\n",
      "w_j: 0.4\n",
      "l: 4\n",
      "regul: 0.001\n",
      "errors: [0.3938669766420479, 1.2768320758539586, 0.47899115693698185, 0.5916860740865229, 0.6910841482835289, 0.9759627341981026, 1.7188936476105534, 1.0922633486322555, 0.7049548158569549, 0.4624319710360715]\n",
      "\n",
      "Selected the following hyper-parameters for LMU\n",
      "regul: 0.001\n",
      "errors: [0.7114710719919806, 0.4491594797881434, 0.820361023367575, 0.4069125326738385, 0.4374249386503305, 1.1323867227254847, 0.639892366387776, 0.46651211938350373, 0.37379674351874387, 0.38531338727330827]\n",
      "\n",
      "Selected the following hyper-parameters for RMM_ESN\n",
      "radius: 0.9\n",
      "sparsity: 0.5\n",
      "regul: 1e-05\n",
      "C: 10000.0\n",
      "errors: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Selected the following hyper-parameters for RMM_CRJ\n",
      "v: 0.5\n",
      "w_c: 0.7\n",
      "w_j: 0.4\n",
      "l: 8\n",
      "regul: 0.001\n",
      "C: 10000.0\n",
      "errors: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Selected the following hyper-parameters for RMM_LMU\n",
      "regul: 1e-05\n",
      "C: 10000.0\n",
      "errors: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5792640805366754, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# perform a hyperoptimization where we test R random hyperparameter\n",
    "# settings for each model and perform num_repeats repeats to obtain\n",
    "# statistics. The hyperparameters with the best mean performance across\n",
    "# repeats will be selected\n",
    "\n",
    "hyper_R = 10\n",
    "hyper_num_repeats = 10\n",
    "\n",
    "# try to load the selected hyperparameters from file\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "hyperparam_path = '%s_hyperparams.json' % task\n",
    "if os.path.isfile(hyperparam_path):\n",
    "    with open(hyperparam_path, 'r') as hyperparam_file:\n",
    "        hyperparams = json.load(hyperparam_file)\n",
    "else:\n",
    "    # generate random parameter combination for all models\n",
    "    hyperparams = {}\n",
    "    for model in models:\n",
    "        hyperparams[model] = []\n",
    "        for r in range(hyper_R):\n",
    "            params_r = {}\n",
    "            hyperparams[model].append(params_r)\n",
    "            # sample a novel random combination of hyper parameters\n",
    "            # for the current model\n",
    "            for key in hyperparam_ranges[model]:\n",
    "                param_range = hyperparam_ranges[model][key]\n",
    "                value = param_range[random.randrange(len(param_range))]\n",
    "                params_r[key] = value\n",
    "            # set up an extra key for the errors\n",
    "            params_r['errors'] = []\n",
    "\n",
    "    for repeat in range(hyper_num_repeats):\n",
    "        print('--- repeat %d of %d ---' % (repeat+1, hyper_num_repeats))\n",
    "        # sample a finite state machine but exclude trivial ones\n",
    "        while True:\n",
    "            delta, rho = fsm.sample_fsm(num_states, num_in_symbols, num_out_symbols)\n",
    "            if len(np.unique(rho)) > 1:\n",
    "                break\n",
    "        # generate the according training data\n",
    "        Xs, Qs, Ys = generate_seq(delta, rho)\n",
    "        # now iterate over all models\n",
    "        for model in models:\n",
    "            print('-- model: %s --' % model)\n",
    "            # and iterate over all parameter combinations for this model\n",
    "            min_rmse = np.inf\n",
    "            for params_r in hyperparams[model]:\n",
    "                # set up a model instance\n",
    "                net = setup_model(model, params_r)\n",
    "                # fit the model to the data\n",
    "                if model.startswith('RMM_'):\n",
    "                    net.fit(Xs, Qs, Ys)\n",
    "                else:\n",
    "                    net.fit(Xs, Ys)\n",
    "                # measure the RMSE on the test data\n",
    "                mse = 0.\n",
    "                for i in range(N_test):\n",
    "                    Ypred = net.predict(Xs_test_one_hot[i])\n",
    "                    Yexp, _ = fsm.label_sequence(Xs_test[i], delta, rho)\n",
    "                    mse   += np.mean((Ypred.squeeze() - Yexp) ** 2)\n",
    "                rmse = np.sqrt(mse / N_test)\n",
    "                params_r['errors'].append(rmse)\n",
    "                if rmse < min_rmse:\n",
    "                    min_rmse = rmse\n",
    "            print('best rmse: %g' % min_rmse)\n",
    "    # write the results to a JSON file\n",
    "    with open(hyperparam_path, 'w') as hyperparam_file:\n",
    "        json.dump(hyperparams, hyperparam_file)\n",
    "\n",
    "# select best hyperparameters for each model\n",
    "hyperparams_opt = {}\n",
    "for model in models:\n",
    "    min_err = np.inf\n",
    "    for params_r in hyperparams[model]:\n",
    "        if np.mean(params_r['errors']) < min_err:\n",
    "            min_err = np.mean(params_r['errors'])\n",
    "            hyperparams_opt[model] = params_r\n",
    "    print('\\nSelected the following hyper-parameters for %s' % model)\n",
    "    for key in hyperparams_opt[model]:\n",
    "        print('%s: %s' % (key, str(hyperparams_opt[model][key])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- repeat 1 of 20 ---\n",
      "--- repeat 2 of 20 ---\n",
      "--- repeat 3 of 20 ---\n",
      "--- repeat 4 of 20 ---\n",
      "--- repeat 5 of 20 ---\n",
      "--- repeat 6 of 20 ---\n",
      "--- repeat 7 of 20 ---\n",
      "--- repeat 8 of 20 ---\n",
      "--- repeat 9 of 20 ---\n",
      "--- repeat 10 of 20 ---\n",
      "--- repeat 11 of 20 ---\n",
      "--- repeat 12 of 20 ---\n",
      "--- repeat 13 of 20 ---\n",
      "--- repeat 14 of 20 ---\n",
      "--- repeat 15 of 20 ---\n",
      "--- repeat 16 of 20 ---\n",
      "--- repeat 17 of 20 ---\n",
      "--- repeat 18 of 20 ---\n",
      "--- repeat 19 of 20 ---\n",
      "--- repeat 20 of 20 ---\n"
     ]
    }
   ],
   "source": [
    "# set up the number of repeats for the actual experiment\n",
    "R = 20\n",
    "\n",
    "# perform the actual experiment in a crossvalidation\n",
    "errors   = np.zeros((len(models), R))\n",
    "errors_with_inference = np.zeros((len(models)+1, R))\n",
    "runtimes = np.zeros((len(models), R))\n",
    "runtimes_with_inference = np.zeros((len(models)+1, R))\n",
    "\n",
    "import time\n",
    "\n",
    "for r in range(R):\n",
    "    print('--- repeat %d of %d ---' % (r+1, R))\n",
    "    # sample a finite state machine but exclude trivial ones\n",
    "    while True:\n",
    "        delta, rho = fsm.sample_fsm(num_states, num_in_symbols, num_out_symbols)\n",
    "        if len(np.unique(rho)) > 1:\n",
    "            break\n",
    "    for with_inference in [False, True]:\n",
    "        # generate the according training data\n",
    "        if with_inference:\n",
    "            start_time = time.time()\n",
    "            Xs, Qs, Ys, delta2, rho2 = generate_seq(delta, rho, with_inference)\n",
    "            # check error that is purely due to automaton learning difficulaties\n",
    "            mse = 0.\n",
    "            for i in range(N_test):\n",
    "                Ypred, _ = fsm.label_sequence(Xs_test[i], delta2, rho2)\n",
    "                Yexp, _  = fsm.label_sequence(Xs_test[i], delta, rho)\n",
    "                mse += np.mean((Ypred - Yexp) ** 2)\n",
    "            rmse = np.sqrt(mse / N_test)\n",
    "            runtimes_with_inference[-1, r] = time.time() - start_time\n",
    "            errors_with_inference[-1, r] = rmse\n",
    "        else:\n",
    "            Xs, Qs, Ys = generate_seq(delta, rho, with_inference)\n",
    "        # now iterate over all models\n",
    "        for model_idx in range(len(models)):\n",
    "            model = models[model_idx]\n",
    "            # print('-- model: %s --' % model)\n",
    "            # set up the model with the best selected hyperparameters\n",
    "            start_time = time.time()\n",
    "            net = setup_model(model, hyperparams_opt[model])\n",
    "            # fit the model to the data\n",
    "            if model.startswith('RMM_'):\n",
    "                net.fit(Xs, Qs, Ys)\n",
    "            else:\n",
    "                net.fit(Xs, Ys)\n",
    "            # measure the RMSE on the test data\n",
    "            mse = 0.\n",
    "            for i in range(N_test):\n",
    "                Ypred = net.predict(Xs_test_one_hot[i])\n",
    "                Yexp, _ = fsm.label_sequence(Xs_test[i], delta, rho)\n",
    "                mse   += np.mean((Ypred.squeeze() - Yexp) ** 2)\n",
    "            rmse = np.sqrt(mse / N_test)\n",
    "            if with_inference:\n",
    "                runtimes_with_inference[model_idx, r] = time.time() - start_time\n",
    "                errors_with_inference[model_idx, r] = rmse\n",
    "            else:\n",
    "                runtimes[model_idx, r] = time.time() - start_time\n",
    "                errors[model_idx, r] = rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- without inference ---\n",
      "ESN: 0.47029 +- 0.160935 (took 0.213089 seconds)\n",
      "CRJ: 0.604922 +- 0.22382 (took 0.127775 seconds)\n",
      "LMU: 0.541558 +- 0.187286 (took 0.256654 seconds)\n",
      "RMM_ESN: 0 +- 0 (took 0.813254 seconds)\n",
      "RMM_CRJ: 0 +- 0 (took 0.733528 seconds)\n",
      "RMM_LMU: 0 +- 0 (took 0.820162 seconds)\n",
      "--- with inference ---\n",
      "ESN: 0.456468 +- 0.178707 (took 0.199003 seconds)\n",
      "CRJ: 0.611023 +- 0.217696 (took 0.126003 seconds)\n",
      "LMU: 0.559275 +- 0.180837 (took 0.252807 seconds)\n",
      "RMM_ESN: 0.023416 +- 0.0715245 (took 0.812356 seconds)\n",
      "RMM_CRJ: 0.023416 +- 0.0715245 (took 0.714939 seconds)\n",
      "RMM_LMU: 0.023416 +- 0.0715245 (took 0.830829 seconds)\n",
      "inference: 0.023416 +- 0.0715245 (took 0.0138352 seconds)\n"
     ]
    }
   ],
   "source": [
    "print('--- without inference ---')\n",
    "for model_idx in range(len(models)):\n",
    "    print('%s: %g +- %g (took %g seconds)' % (models[model_idx], np.mean(errors[model_idx, :]), np.std(errors[model_idx, :]), np.mean(runtimes[model_idx, :])))\n",
    "print('--- with inference ---')\n",
    "for model_idx in range(len(models)):\n",
    "    print('%s: %g +- %g (took %g seconds)' % (models[model_idx], np.mean(errors_with_inference[model_idx, :]), np.std(errors_with_inference[model_idx, :]), np.mean(runtimes_with_inference[model_idx, :])))\n",
    "print('inference: %g +- %g (took %g seconds)' % (np.mean(errors_with_inference[-1, :]), np.std(errors_with_inference[-1, :]), np.mean(runtimes_with_inference[-1, :])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store results\n",
    "np.savetxt('%s_errors.csv' % task, errors.T, delimiter='\\t', header='\\t'.join(models), comments='')\n",
    "np.savetxt('%s_runtimes.csv' % task, runtimes.T, delimiter='\\t', header='\\t'.join(models), comments='')\n",
    "np.savetxt('%s_errors_with_inference.csv' % task, errors_with_inference.T, delimiter='\\t', header='\\t'.join(models) + '\\tinference', comments='')\n",
    "np.savetxt('%s_runtimes_with_inference.csv' % task, runtimes_with_inference.T, delimiter='\\t', header='\\t'.join(models) + '\\tinference', comments='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
